The process consists of the following steps:
    1) SCRAPING jsons from the site (scraping.py)
    2) EXTRACTION of direct routes from the scraped jsons (extraction.py)
    3) TREATMENT of obtained data to create the datasets for validation etc (treatment.py)
    4) FIXING the prices for specific routes listed in corresponding file (fixing.py)

All nessecary input files are stored in directory 'files/csv':
    - airport_codes_short.csv (binds airport codes with city ids)
    - bbox_short.csv (binds city ids with city geo coordinates)
    - cities.csv (list of city names and city ids)
    - Full_list_with_countries_CLEANED_for_scraping.csv (binds city ids, city names, country names)

Subfolder 'files/currencies' stores the json files with the currency exchange rates (updates if last updating date is later than 1 day ago).    

After processing the scripts, the following subfolders appear in the 'output' folder:
    - /csv_output;
    - /inner_json_output;
    - /json_output.

Below is a list of the output files stored in the folder 'output/csv_output':
    - all_direct_routes_raw.csv - non-ordered file with all avaliable 'raw' data per each of direct routes (output of extraction.py)
    - all_direct_routes_validation.csv - non-ordered file with only the columns relevant to validation purposes (output of treatment.py)
    - all_direct_routes_triples.csv - file containing the routes ordered by triples (from_id, to_id, transport_id) with lowest price (treatment.py)
    - all_direct_valid_routes.csv - the same 'all_direct_routes_triples.csv' file with fixed prices (output of fixing.py)
    - fixed_ids.csv - file containing ids of routes which were already fixed (output of fixing.py)
    - no_id_transport.csv - list of transport types that were not taken into account (output of extraction.py)
    - unknown_currencies - list of currencies that may have been missed due to their absence in existing database of currencies (output of extraction.py)

The output subfolder  'inner_json_output' stores json files for each of valid routes.
The output subfolder 'json_output' stores scraped and zipped json files.

Whole process (exluding price fixing) can be runed by only one 'scrapRome2Rio.py' script.

The 'fixing.py' script aimed to fix prices for the specific routes stored in csv file(s) by path 'files/routes_to_fix/'. 
    To fix from only one file run:
                                    $ python3 fixing.py -f [filename].csv

    Or run to fix from batch of files:
                                        $ python3 fixing.py -b 

Folder 'logs' stores the corresponding log-files for each stage of the process.
Script 'hotels.py' extracts the links from the scraped json files and stores it in json file in the folder 'files/hotels'.